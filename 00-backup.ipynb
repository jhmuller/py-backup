{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp backup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-detail",
   "metadata": {},
   "source": [
    "# backup\n",
    " > API details\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python3\n",
    "# backupToZip.py\n",
    "# Copies an entire folder and its contents into\n",
    "# a zip file whose filename increments.\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "import inspect\n",
    "import warnings\n",
    "import traceback\n",
    "import hashlib\n",
    "import zlib\n",
    "import zipfile\n",
    "import pickle\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path, PurePath\n",
    "from collections import OrderedDict\n",
    "__version__ = \"0.1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force warnings.warn() to omit the source code line in the message\n",
    "#formatwarning_orig = warnings.formatwarning\n",
    "#warnings.formatwarning = lambda message, category, filename, lineno, line=None: \\\n",
    "#    formatwarning_orig(message, category, filename, lineno, line='')\n",
    "\n",
    "def warning_on_one_line(message, category, filename, lineno, file=None, line=None):\n",
    "    return ' %s:%s: %s:%s' % (filename, lineno, category.__name__, message)\n",
    "warnings.formatwarning = warning_on_one_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbosity = 0\n",
    "mlist = list(filter(lambda x: inspect.ismodule(x[1]), locals().items()))\n",
    "if 'verbosity' in locals().keys() and verbosity > 0:\n",
    "  print(mlist)\n",
    "vi = sys.version_info\n",
    "print(\"version {0}.{1}.{2} of Python\".format(vi.major, vi.minor, vi.micro))\n",
    "for name, mod in mlist:\n",
    "    mname = name\n",
    "    if name.startswith(\"__\"):\n",
    "        continue\n",
    "    if hasattr(mod, \"__version__\"):\n",
    "        mname = name\n",
    "        if hasattr(mod, \"__path__\"):\n",
    "            mname = os.path.split(mod.__path__[0])[1]\n",
    "        print(\"version {1} of {0} as {2} \".format(mname, name, mod.__version__))\n",
    "    elif hasattr(mod, \"__file__\") and \"site-packages\" in mod.__file__:\n",
    "        print(\"No __version__ for {0} as {1}\".format(mname, name))\n",
    "print(datetime.datetime.now())\n",
    "del mod\n",
    "del name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whoami():\n",
    "    return sys._getframe(1).f_code.co_name\n",
    "  \n",
    "def sha_256(fpath, size=4096):\n",
    "    m = hashlib.sha256()\n",
    "    with open(fpath, mode='rb') as fp:\n",
    "        for chunk in iter(lambda: fp.read(size), b''):\n",
    "            m.update(chunk)\n",
    "    return m.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_exc(e, rethrow=False):\n",
    "    (extype, exval, tb) = sys.exc_info()\n",
    "    print(\"extype= {0}, exval= {1}\".format(extype, exval))  \n",
    "    tblist = traceback.extract_tb(tb)\n",
    "    lines = traceback.format_list(tblist)\n",
    "    for line in lines:\n",
    "      print(line)\n",
    "    if rethrow:\n",
    "      raise RuntimeError(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_zip(infilepath, zipfilepath, \n",
    "                   compression=zipfile.ZIP_DEFLATED,\n",
    "                   compresslevel=zlib.Z_DEFAULT_COMPRESSION,\n",
    "                   verbosity=0):\n",
    "  import zipfile\n",
    "  if verbosity > 1:\n",
    "    print(\"creating zipfile {0} from {1} <{2}>\".format(infilepath, zipfilepath,\n",
    "                                                      datetime.datetime.now()))\n",
    "  zf = zipfile.ZipFile(zipfilepath, mode='w', compression=compression,\n",
    "                      compresslevel=compresslevel)\n",
    "  try:\n",
    "    if verbosity > 1:\n",
    "      print(\"adding {0}\".format(infilepath))\n",
    "    zf.write(infilepath)\n",
    "  finally:\n",
    "    if verbosity > 1:\n",
    "      print('Done, closing <{0}>'.format(datetime.datetime.now()))\n",
    "    zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path2string(fpath, sep=\"_\", verbosity=0):\n",
    "    pathstring = \"\"\n",
    "    pathleft = fpath\n",
    "    while True:\n",
    "        pathleft, tail = os.path.split(pathleft)\n",
    "        if len(tail) == 0:\n",
    "            break\n",
    "        pathstring = tail + sep + pathstring\n",
    "    if verbosity > 0:\n",
    "        print(\"pathstring= {0}\".format(pathstring)) \n",
    "    return pathstring\n",
    "  \n",
    "  \n",
    "def check_outdir(outdir, create=True, verbosity=0):\n",
    "    if os.path.isdir(outdir):\n",
    "      return outdir\n",
    "    \n",
    "    warnings.warn(\"{0} not a dir\".format(outdir))      \n",
    "    if not create:\n",
    "      return None\n",
    "    \n",
    "    if verbosity > 0:\n",
    "      print(\"trying to create {0}\".format(outdir))\n",
    "    os.makedirs(outdir)\n",
    "    if not os.path.isdir(outdir):\n",
    "        raise RuntimeError(\"Cannot make dir= '{0}'\".format(outdir)) \n",
    "    return outdir\n",
    "    \n",
    "def make_metafilepath(outdir, basename=\"generic\",\n",
    "                     sep = \"_\", ext=\"\",\n",
    "                     verbosity=0):\n",
    "    # Figure out the filename this code should used based on \n",
    "    # what files already exist.  \n",
    "    while True:\n",
    "        nowstr = datetime.datetime.now().strftime(format=\"%Y-%m-%d__%H_%M_%S\") \n",
    "        outfilename = basename + sep + nowstr + ext\n",
    "        if not os.path.exists(outfilename):\n",
    "            break\n",
    "        number = number + 1\n",
    "    if verbosity > 0:\n",
    "        print(\"Creating '{0}'\".format(outfilename))\n",
    "\n",
    "    outfilepath = os.path.join(outdir, outfilename)    \n",
    "    return outfilepath\n",
    "  \n",
    "def make_tempfilepath(folder, base, sep=\"_\", ext=\"\", verbosity=0):\n",
    "    number = 1\n",
    "    while True:\n",
    "        nowstr = datetime.datetime.now().strftime(format=\"%Y-%m-%d__%H_%M_%S\")  \n",
    "        filename = base + sep +  nowstr + ext\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            break\n",
    "        number = number + 1 \n",
    "    return filepath\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_backup_metafile(folder, filename, verbosity=0):\n",
    "  filepath = os.path.join(folder, filename)\n",
    "  if not os.path.isfile(filepath):\n",
    "    raise ValueError(\"Cannot find file {0} in folder {1}\".format(filename, folder))\n",
    "  data = []\n",
    "  with open(filepath, \"rb\") as fp:\n",
    "      while True:\n",
    "        try:\n",
    "          x = pickle.load(fp)      \n",
    "          data.append(x)\n",
    "        except EOFError as error:\n",
    "          # this is expected\n",
    "          break\n",
    "        except Exception as e:\n",
    "          handle_exc(e)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_folder_filename(folder, filename):\n",
    "  filepath = os.path.join(folder, filename)\n",
    "  if not os.path.isfile(filepath):\n",
    "    raise ValueError(\"Cannot find file {0} in folder {1}\".format(filename, folder))\n",
    "  meta = import_backup_metafile(folder=folder, filename=filename)\n",
    "  if len(meta) == 0:\n",
    "    warnings.warn(\"Empty metafile {0} in {1}\".format(filename, folder))\n",
    "    return False  \n",
    "  return True\n",
    "\n",
    "\n",
    "def get_meta(folder, filename):\n",
    "  if not check_folder_filename(folder, filename):\n",
    "    return False\n",
    "  \n",
    "  meta = import_backup_metafile(folder=folder, filename=filename)\n",
    "  if len(meta) == 0:\n",
    "    warnings.warn(\"Empty metafile {0} in {1}\".format(filename, folder))\n",
    "    return None \n",
    "  \n",
    "  if not meta[0]['rec_type'] == \"meta_info\":\n",
    "    msg = \"file= {0}, folder= {1}\\n first elem is not meta {2}\".format(filename, folder, meta[0])\n",
    "    warnings.warn(msg)\n",
    "    return None\n",
    "  return meta\n",
    "\n",
    "def get_meta_fields(folder, filename):\n",
    "  if not check_folder_filename(folder, filename):\n",
    "    return False\n",
    "  \n",
    "  meta = get_meta(folder, filename)\n",
    "  if not meta:\n",
    "    return None\n",
    "  \n",
    "  res = {\"meta_info\": list(meta[0].keys())}\n",
    "  if len(meta) > 1:\n",
    "    res[\"file_info\"] = list(meta[1].keys())\n",
    "  return res\n",
    "  \n",
    "  \n",
    "def get_meta_info(folder, filename, meta_fields=None, \n",
    "                    file_info_fields=None, verbosity=0):\n",
    "  if not check_folder_filename(folder, filename):\n",
    "    return False\n",
    "  \n",
    "  meta = get_meta(folder, filename)\n",
    "  if not meta:\n",
    "    return None\n",
    "  res = \"\"\n",
    "  act_fields = get_meta_fields(folder, filename)\n",
    "  fields = []\n",
    "  if meta_fields:\n",
    "    for f in meta_fields:\n",
    "      if f in act_fields['meta_info']:\n",
    "        fields.append(f)\n",
    "      else:\n",
    "        warnings.warn(\" requested meta_field {0} not in meta_fields\".format(f))\n",
    "  else:\n",
    "    fields = act_fields['meta_info']      \n",
    "\n",
    "  msglst = [\"{0}: {1}\".format(f, meta[0][f]) for f in fields]\n",
    "  res += \", \".join(msglst)\n",
    "  res += \"\\n\"\n",
    "  \n",
    "  nfiles = sum([int(e['rec_type']=='file_info') for e in meta])\n",
    "  res += \"{0} files\".format(nfiles)\n",
    "  res += \"\\n\"\n",
    "  \n",
    "  fields = []\n",
    "  if file_info_fields:\n",
    "    for f in file_info_fields:\n",
    "      if f in act_fields['file_info']:\n",
    "        fields.append(f)\n",
    "      else:\n",
    "        warnings.warn(\" requested file_info_field {0} not in file_info_fields\".format(f))\n",
    "  else:\n",
    "    fields = act_fields['file_info'] \n",
    "    \n",
    "  for i, elem in enumerate(meta[1:]):\n",
    "    msglst = [\"[{0}]: {1}: {2}\".format(i, f, elem[f]) for f in fields]\n",
    "    res += \", \".join(msglst)\n",
    "    res += \"\\n\"\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_make_path(thepath, verbosity=0):\n",
    "    if os.path.isdir(thepath):\n",
    "      return thepath\n",
    "    \n",
    "    warnings.warn(\"{0} not a dir\".format(thepath))      \n",
    "        \n",
    "    if verbosity > 0:\n",
    "      print(\"trying to create {0}\".format(thepath))\n",
    "      \n",
    "    os.makedirs(thepath)\n",
    "    if not os.path.isdir(thepath):\n",
    "        raise RuntimeError(\"Cannot make dir= '{0}'\".format(thepath)) \n",
    "        \n",
    "    return thepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_make_path(\"C:\\\\backup\\\\foo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_colors = {\n",
    "  \"black\": \"\\033[90m\",\n",
    "  \"red\": \"\\033[91m\",  \n",
    "  \"green\": \"\\033[92m\",\n",
    "  \"yellow\": \"\\033[93m\",\n",
    "  \"blue\": \"\\033[94m\",\n",
    "  \"gray\": \"\\033[97m\"\n",
    "    }\n",
    "bg_colors = {\n",
    "  \"black\": \"\\033[100m\",\n",
    "  \"red\": \"\\033[101m\",  \n",
    "  \"green\": \"\\033[102m\",\n",
    "  \"yellow\": \"\\033[103m\",\n",
    "  \"blue\": \"\\033[104m\",\n",
    "  \"gray\": \"\\033[107m\"\n",
    "    }\n",
    "\n",
    "effects = {\n",
    "  \"end\" : \"\\033[0m\",\n",
    "  \"bold\" : \"\\033[1m\",\n",
    "  \"underline\" : \"\\033[4m\",  \n",
    "  \"blackback\" : \"\\033[7m\",    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup(origpath, destpath, \n",
    "            include_exts=None,\n",
    "            exclude_exts=None,\n",
    "            comp_thresh = 0.9,\n",
    "            compression=zipfile.ZIP_DEFLATED,\n",
    "            compresslevel=zlib.Z_DEFAULT_COMPRESSION,       \n",
    "                testing=False,\n",
    "                verbosity=0):\n",
    "    \n",
    "    # Backup the entire contents of \"folder\" into a zip file.\n",
    "    if verbosity > 0:\n",
    "        print(\"function: {0}\".format(whoami()))\n",
    "        print(\"origpath= {0} destpath= {1}\".format(origpath, destpath))\n",
    "        print(\"testing: {0}\".format(testing))\n",
    "        \n",
    "    pp_origpath = PurePath(origpath)\n",
    "    if not pp_origpath.is_absolute():\n",
    "      warnings.warn(\"origpath must be absolute, {0}\".format(origpath))\n",
    "      \n",
    "    pp_destpath = PurePath(destpath)\n",
    "    if not pp_destpath.is_absolute():\n",
    "      warnings.warn(\"destpath must be absolute, {0}\".format(destpath)) \n",
    "      \n",
    "    if (origpath == destpath) or (pp_origpath == pp_destpath):\n",
    "      msg = \"origpath cannot be same as destpath\"\n",
    "      msg += \"Please choose a different destpath so files will not be overwritten\"\n",
    "      raise RuntimeError(msg)\n",
    "      \n",
    "    check_make_path(destpath, verbosity=verbosity)\n",
    "    \n",
    "    dest_drive = pp_destpath.drive\n",
    "    dest_folder = os.sep.join(pp_destpath.parts[1:])  \n",
    "\n",
    "    orig_drive = pp_origpath.drive\n",
    "    orig_folder = os.sep.join(pp_origpath.parts[1:])\n",
    "    \n",
    "    for xname in ('include_exts', 'exclude_exts'):\n",
    "        x = locals()[xname]\n",
    "        if isinstance(x, str):\n",
    "            x = [x]\n",
    "        if isinstance(x, list):\n",
    "            if len(x) == 0:\n",
    "                x = None\n",
    "        elif x is not None:\n",
    "            raise ValueError(\"{0} should be None or string or list of strings\")\n",
    "        if verbosity > 1:\n",
    "            print(\"{0}: {1}\".format(xname, x))\n",
    "        locals()[xname] = x\n",
    "      \n",
    "    if True:\n",
    "      metafilepath = make_metafilepath(outdir=destpath,\n",
    "                                     basename=\"backup_meta\",\n",
    "                                     ext=\".pickle\",\n",
    "                                     verbosity=verbosity)\n",
    "      metafilename = os.path.split(metafilepath)[1]\n",
    "      ddict = OrderedDict()\n",
    "      ddict['rec_type'] = \"meta_info\"\n",
    "      ddict['comp_thresh'] = comp_thresh\n",
    "      ddict['compression'] = compression\n",
    "      ddict['compresslevel'] = compresslevel\n",
    "      ddict['backup_version'] = __version__\n",
    "      ddict['python_version'] = str(sys.version_info)\n",
    "      ddict['zlib_version'] = zlib.__version__\n",
    "      ddict[\"now\"] = datetime.datetime.now()\n",
    "      \n",
    "      with open(metafilepath, mode='wb') as meta_fp:\n",
    "        pickle.dump(ddict, meta_fp)      \n",
    "\n",
    "    # Walk the entire folder tree and compress the files in each folder.\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(origpath, topdown=True):\n",
    "        pp_dirpath = PurePath(dirpath)\n",
    "        dirdrive = pp_dirpath.drive\n",
    "        dirfolder = os.sep.join(pp_dirpath.parts[1:])\n",
    "         \n",
    "        this_outpath = os.path.join(destpath, dirfolder)\n",
    "        \n",
    "        if verbosity > 0:\n",
    "            print(\"Adding files from '{0}' to '{1}'\".format(dirpath, this_outpath))        \n",
    "        for filename in filenames:\n",
    "            if filename == metafilename:\n",
    "              continue\n",
    "            base, ext = os.path.splitext(filename)\n",
    "            if include_exts is not None:\n",
    "                if ext not in  include_exts:\n",
    "                    if verbosity > 1:\n",
    "                        print(\"  Skipping {0}, {1} not in include_exts\".format(filename))\n",
    "                    continue\n",
    "            if exclude_exts is not None:\n",
    "                if ext in exlude_exts:\n",
    "                    if verbosity > 1:\n",
    "                        print(\"  Skipping {0}, {1}  in include_exts\".format(filename))\n",
    "                    continue\n",
    "            if filename.endswith('.pickle'):\n",
    "                continue # don't backup the backup pickle files\n",
    "                \n",
    "            origfilepath = os.path.join(dirpath, filename)\n",
    "            if testing and (verbosity > 0):\n",
    "                print(\"  adding {0}\".format(filename))\n",
    "            else:\n",
    "              try:\n",
    "                ddict = OrderedDict()\n",
    "                zipfilepath = make_tempfilepath(destpath, base=\"temp\", ext=\".zip\", \n",
    "                                                verbosity=verbosity)\n",
    "                \n",
    "                create_new_zip(origfilepath, zipfilepath)\n",
    "                 \n",
    "                zfile = zipfile.ZipFile(zipfilepath, mode='r')\n",
    "                nzipelems = len(list(zfile.infolist()))\n",
    "                if nzipelems > 1:\n",
    "                  msg = \"Uh-Oh, {0} elements in zipfile {1}\".format(zipfilepath)\n",
    "                  warnings.warn(warn)\n",
    "                zfile.close()\n",
    "\n",
    "                orig_size = os.path.getsize(origfilepath)\n",
    "                comp_size = os.path.getsize(zipfilepath)\n",
    "                ddict['rec_type'] = \"file_info\"\n",
    "                ddict['filename'] = filename   \n",
    "                ddict['folder'] = dirpath               \n",
    "                ddict['filepath'] = origfilepath\n",
    "                ddict['orig_size'] = orig_size\n",
    "                ddict['comp_size'] = comp_size   \n",
    "                ddict['zipname'] = zfile.filename               \n",
    "                ddict['sha256'] = sha_256(origfilepath, size=4096)\n",
    "                dt_fmt = '%Y-%m-%dT%H:%M:%S'\n",
    "                ddict['ctime'] = datetime.datetime.fromtimestamp(os.path.getctime(origfilepath)).strftime(dt_fmt)\n",
    "                ddict['mtime'] = datetime.datetime.fromtimestamp(os.path.getmtime(origfilepath)).strftime(dt_fmt) \n",
    "                comp_ratio = np.nan\n",
    "                if orig_size == 0:\n",
    "                  warnings.warn(\"{0} in {1} size is {2}\".format(filename, origpath, orig_size))\n",
    "\n",
    "                else:\n",
    "                  comp_ratio = float(comp_size)/orig_size \n",
    "                ddict['comp_ratio'] =  comp_ratio\n",
    "                \n",
    "                if ddict['comp_ratio'] > comp_thresh:\n",
    "                  ddict['compressed'] = False\n",
    "                  infilepath = origfilepath\n",
    "                else:\n",
    "                  infilepath = zipfilepath\n",
    "                  ddict['compressed'] = True                  \n",
    "\n",
    "\n",
    "                # write metadata\n",
    "                with open(metafilepath, mode='ab') as meta_fp:                \n",
    "                  pickle.dump(ddict, meta_fp)\n",
    "                \n",
    "                this_outfilename = filename\n",
    "                if ddict['compressed']:\n",
    "                  this_outfilebase = os.path.splitext(ddict['filename'])[0]                   \n",
    "                  this_outfilename = this_outfilebase + \".zip\"\n",
    "                outfilepath = os.path.join(this_outpath, this_outfilename) \n",
    "\n",
    "                if verbosity > 0:\n",
    "                    msg = \"filename: {0}, filepath: {1}\".format(filename, origfilepath)\n",
    "                    msg += \", osize= {0}, csize= {1}\".format(orig_size, comp_size)\n",
    "                    msg += \", compressed= {0}\".format(ddict['compressed'])\n",
    "                    msg += \"\\n infilepath: {0} outfilepath: {1}\".format(infilepath, outfilepath)\n",
    "                    #print(\"sha_256= {0}\".format(ddict['sha256']))\n",
    "                    print(msg)\n",
    "                    \n",
    "                # write the file\n",
    "                if not testing:\n",
    "                  if verbosity > 0:\n",
    "                    print(\" Copying file\")\n",
    "                  check_make_path(outfilepath, verbosity=verbosity)\n",
    "                  shutil.copy(infilepath, outfilepath)    \n",
    "                \n",
    "                  # remove the temp zipfile\n",
    "                if os.path.isfile(zipfilepath):\n",
    "                  zfile.close()\n",
    "                  try:\n",
    "                    os.remove(zipfilepath)\n",
    "                  except Exception as err:\n",
    "                    handle_exc(err, rethrow=False)\n",
    "                else:\n",
    "                  warnings.warn(\"can't find zipfile {0}\".format(zipfilepath))\n",
    "              except Exception as e:\n",
    "                handle_exc(e, rethrow=False)\n",
    "\n",
    "    if True:\n",
    "        if verbosity > 0:\n",
    "            print(\"Done\")\n",
    "        meta_fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder = os.path.join(\"C:\\\\\", \"Users\", os.getenv(\"USERNAME\"),\"OneDrive\", \"Documents\") \n",
    "print(\"folder= {0}\".format(folder))\n",
    "pp = PurePath(folder)\n",
    "os.sep.join(pp.parts[1:])\n",
    "pp.is_absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    print(\"folder= {0}\".format(folder))\n",
    "    N = 10\n",
    "    print(\"files: {0}\".format(os.listdir(folder)[:N]))\n",
    "    backup(origpath=folder, destpath=\"F:\\\\backup\\\\\", testing=False, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipfilepath = os.path.join('F:\\\\', 'backup', 'temp_2021-01-22__10_42_13.zip')\n",
    "zfile = zipfile.ZipFile(zipfilepath, mode='r')  \n",
    "zfile.filename\n",
    "zfile.getinfo(zfile.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zfile.infolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(zfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover(folder, meta_filename, filelist, \n",
    "            outdir, create_outdir=False,\n",
    "            chunk_size = 10**6,\n",
    "            overwrite=False, testing=True, verbosity=0):\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  if not os.path.isdir(folder):\n",
    "    warnings.warn(\"{0} is not a folder\".format(folder))\n",
    "    return None\n",
    "  \n",
    "  meta = get_meta(folder, meta_filename)\n",
    "  \n",
    "  if not meta:\n",
    "    return None  \n",
    "  if len(meta) ==1:\n",
    "    warnings.warn(\"No file_info records\")\n",
    "    return None\n",
    "  res = check_outdir(outdir, create=create_outdir, verbosity=0)  \n",
    "  \n",
    "  filemap = {}\n",
    "  for i, e in enumerate(meta[1:]):\n",
    "    filemap[e['filename']] = i+1 \n",
    "  for filename in filelist:\n",
    "    if filename in filemap.keys():\n",
    "      ei = filemap[filename]\n",
    "      msg = \"Found {0} as entry {1}\".format(filename, ei)\n",
    "      print(msg)\n",
    "      file_info = meta[ei]\n",
    "      print(file_info)\n",
    "      if file_info['compressed']:  \n",
    "        outfilepath = make_tempfilepath(outdir, base=\"temp\", ext=\".zip\", \n",
    "                                                verbosity=verbosity)\n",
    "      else:\n",
    "        outfilepath = os.path.join(outdir, file_info['filename'])\n",
    "      print(\"outfilepath= {0}\".format(outfilepath))\n",
    "      outfilepath = os.path.abspath(outfilepath) # make sure folder is absolute \n",
    "      print(\"outfilepath= {0}\".format(outfilepath))      \n",
    "      infilename = file_info['sha256']\n",
    "      infilepath = os.path.join(folder, infilename)\n",
    "      if not os.path.isfile(infilepath):\n",
    "        warnings.warn(\"Cannot fine backup file {0} in {1}\".format(infilename, folder))\n",
    "        continue\n",
    "      try:\n",
    "        if verbosity > 0:\n",
    "          print(\"copying {0} to {1}\".format(infilepath, outfilepath))\n",
    "        shutil.copy(infilepath, outfilepath)         \n",
    "      except Exception as e:\n",
    "        (extype, exval, tb) = sys.exc_info()\n",
    "        warnings.warn(\"extype= {0}, exval= {1}\\n {2}\".format(extype, exval, tb))  \n",
    "\n",
    "        \n",
    "      if file_info['compressed']:\n",
    "        zipfilepath = outfilepath\n",
    "        outfilepath = os.path.join(outdir, file_info['filename'])\n",
    "        print(\"outfilepath {0}\".format(outfilepath))\n",
    "        if verbosity > 0:\n",
    "          print(\"Unzipping {0} to {1}\".format(zipfilepath, outfilepath))  \n",
    "          \n",
    "        zfile = zipfile.ZipFile(zipfilepath, mode='r')  \n",
    "        for zm in zfile.infolist():\n",
    "          print(zm)\n",
    "        try:\n",
    "          zipname = file_info['zipname']\n",
    "          print(\"zipname= {0}  outfilepath= {1}\".format(zipname, outfilepath))\n",
    "          zfile.extract(member=zipname, \n",
    "                  path=outfilepath, pwd=None)\n",
    "        except Exception as e:\n",
    "          (extype, exval, tb) = sys.exc_info()\n",
    "          warnings.warn(\"extype= {0}, exval= {1}\\n {2}\".format(extype, exval, tb))           \n",
    "          raise Exception(e)\n",
    "        zfile.close() \n",
    "        os.remove(zipfilepath)\n",
    "      \n",
    "      #with open(infilepath, mode='rb') as ifp:\n",
    "      #  with open(outfilepath, mode=\"wb\") as ofp:\n",
    "      #    while True:\n",
    "      #      ifp.read()\n",
    "    else:\n",
    "      msg = \"No entry for {0}\".format(filename)\n",
    "      warnings.warn(msg)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_folder = \"backup\"\n",
    "files = os.listdir(meta_folder)\n",
    "meta_files = [f for f in files if f.endswith(\"pickle\")]\n",
    "meta_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_folder = \"backup\"\n",
    "files = os.listdir(meta_folder)\n",
    "meta_files = [f for f in files if f.endswith(\"pickle\")]\n",
    "meta_filename = meta_files[0]\n",
    "print(meta_filename)\n",
    "#print_meta_info(folder=meta_folder, filename=meta_filename, fields=[''])\n",
    "meta_fields = get_meta_fields(meta_folder, meta_filename)\n",
    "meta_fields\n",
    "res = get_meta_info(folder=meta_folder, filename=meta_filename, meta_fields=None, \n",
    "              file_info_fields=['filename', 'zipname', 'orig_size'])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "recover(folder=meta_folder, meta_filename=meta_filename,\n",
    "        filelist=['mail-loop.PNG'], \n",
    "            outdir='recovered', create_outdir=True,\n",
    "            overwrite=True, testing=False, verbosity=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_filename = \"backup_meta_1.pickle\"\n",
    "meta_folder = \"backup\"\n",
    "meta = import_backup_metafile(folder=meta_folder, filename=meta_filename)\n",
    "meta[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backup",
   "language": "python",
   "name": "backup"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
